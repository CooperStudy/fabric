//line /home/cooper/go/src/github.com/hyperledger/fabric/common/ledger/blkstorage/fsblkstorage/blocks_itr.go:1
/*
Copyright IBM Corp. 2016 All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

		 http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

package fsblkstorage; import _cover_atomic_ "sync/atomic"

import (
	"sync"

	"github.com/hyperledger/fabric/common/ledger"
)

// blocksItr - an iterator for iterating over a sequence of blocks
type blocksItr struct {
	mgr                  *blockfileMgr
	maxBlockNumAvailable uint64
	blockNumToRetrieve   uint64
	stream               *blockStream
	closeMarker          bool
	closeMarkerLock      *sync.Mutex
}

func newBlockItr(mgr *blockfileMgr, startBlockNum uint64) *blocksItr {_cover_atomic_.AddUint32(&GoCover_6_386431356532613230373239.Count[0], 1);
	mgr.cpInfoCond.L.Lock()
	defer mgr.cpInfoCond.L.Unlock()
	return &blocksItr{mgr, mgr.cpInfo.lastBlockNumber, startBlockNum, nil, false, &sync.Mutex{}}
}

func (itr *blocksItr) waitForBlock(blockNum uint64) uint64 {_cover_atomic_.AddUint32(&GoCover_6_386431356532613230373239.Count[1], 1);
	itr.mgr.cpInfoCond.L.Lock()
	defer itr.mgr.cpInfoCond.L.Unlock()
	for itr.mgr.cpInfo.lastBlockNumber < blockNum && !itr.shouldClose() {_cover_atomic_.AddUint32(&GoCover_6_386431356532613230373239.Count[3], 1);
		logger.Debugf("Going to wait for newer blocks. maxAvailaBlockNumber=[%d], waitForBlockNum=[%d]",
			itr.mgr.cpInfo.lastBlockNumber, blockNum)
		itr.mgr.cpInfoCond.Wait()
		logger.Debugf("Came out of wait. maxAvailaBlockNumber=[%d]", itr.mgr.cpInfo.lastBlockNumber)
	}
	_cover_atomic_.AddUint32(&GoCover_6_386431356532613230373239.Count[2], 1);return itr.mgr.cpInfo.lastBlockNumber
}

func (itr *blocksItr) initStream() error {_cover_atomic_.AddUint32(&GoCover_6_386431356532613230373239.Count[4], 1);
	var lp *fileLocPointer
	var err error
	if lp, err = itr.mgr.index.getBlockLocByBlockNum(itr.blockNumToRetrieve); err != nil {_cover_atomic_.AddUint32(&GoCover_6_386431356532613230373239.Count[7], 1);
		return err
	}
	_cover_atomic_.AddUint32(&GoCover_6_386431356532613230373239.Count[5], 1);if itr.stream, err = newBlockStream(itr.mgr.rootDir, lp.fileSuffixNum, int64(lp.offset), -1); err != nil {_cover_atomic_.AddUint32(&GoCover_6_386431356532613230373239.Count[8], 1);
		return err
	}
	_cover_atomic_.AddUint32(&GoCover_6_386431356532613230373239.Count[6], 1);return nil
}

func (itr *blocksItr) shouldClose() bool {_cover_atomic_.AddUint32(&GoCover_6_386431356532613230373239.Count[9], 1);
	itr.closeMarkerLock.Lock()
	defer itr.closeMarkerLock.Unlock()
	return itr.closeMarker
}

// Next moves the cursor to next block and returns true iff the iterator is not exhausted
func (itr *blocksItr) Next() (ledger.QueryResult, error) {_cover_atomic_.AddUint32(&GoCover_6_386431356532613230373239.Count[10], 1);
	if itr.maxBlockNumAvailable < itr.blockNumToRetrieve {_cover_atomic_.AddUint32(&GoCover_6_386431356532613230373239.Count[15], 1);
		itr.maxBlockNumAvailable = itr.waitForBlock(itr.blockNumToRetrieve)
	}
	_cover_atomic_.AddUint32(&GoCover_6_386431356532613230373239.Count[11], 1);itr.closeMarkerLock.Lock()
	defer itr.closeMarkerLock.Unlock()
	if itr.closeMarker {_cover_atomic_.AddUint32(&GoCover_6_386431356532613230373239.Count[16], 1);
		return nil, nil
	}
	_cover_atomic_.AddUint32(&GoCover_6_386431356532613230373239.Count[12], 1);if itr.stream == nil {_cover_atomic_.AddUint32(&GoCover_6_386431356532613230373239.Count[17], 1);
		logger.Debugf("Initializing block stream for iterator. itr.maxBlockNumAvailable=%d", itr.maxBlockNumAvailable)
		if err := itr.initStream(); err != nil {_cover_atomic_.AddUint32(&GoCover_6_386431356532613230373239.Count[18], 1);
			return nil, err
		}
	}
	_cover_atomic_.AddUint32(&GoCover_6_386431356532613230373239.Count[13], 1);nextBlockBytes, err := itr.stream.nextBlockBytes()
	if err != nil {_cover_atomic_.AddUint32(&GoCover_6_386431356532613230373239.Count[19], 1);
		return nil, err
	}
	_cover_atomic_.AddUint32(&GoCover_6_386431356532613230373239.Count[14], 1);itr.blockNumToRetrieve++
	return deserializeBlock(nextBlockBytes)
}

// Close releases any resources held by the iterator
func (itr *blocksItr) Close() {_cover_atomic_.AddUint32(&GoCover_6_386431356532613230373239.Count[20], 1);
	itr.mgr.cpInfoCond.L.Lock()
	defer itr.mgr.cpInfoCond.L.Unlock()
	itr.closeMarkerLock.Lock()
	defer itr.closeMarkerLock.Unlock()
	itr.closeMarker = true
	itr.mgr.cpInfoCond.Broadcast()
	if itr.stream != nil {_cover_atomic_.AddUint32(&GoCover_6_386431356532613230373239.Count[21], 1);
		itr.stream.close()
	}
}

var GoCover_6_386431356532613230373239 = struct {
	Count     [22]uint32
	Pos       [3 * 22]uint32
	NumStmt   [22]uint16
} {
	Pos: [3 * 22]uint32{
		35, 39, 0x20046, // [0]
		41, 44, 0x46003c, // [1]
		50, 50, 0x270002, // [2]
		44, 49, 0x30046, // [3]
		53, 56, 0x57002a, // [4]
		59, 59, 0x6b0002, // [5]
		62, 62, 0xc0002, // [6]
		56, 58, 0x30057, // [7]
		59, 61, 0x3006b, // [8]
		65, 69, 0x2002a, // [9]
		72, 73, 0x37003a, // [10]
		76, 78, 0x150002, // [11]
		81, 81, 0x170002, // [12]
		87, 88, 0x100002, // [13]
		91, 92, 0x290002, // [14]
		73, 75, 0x30037, // [15]
		78, 80, 0x30015, // [16]
		81, 83, 0x2a0017, // [17]
		83, 85, 0x4002a, // [18]
		88, 90, 0x30010, // [19]
		96, 103, 0x17001f, // [20]
		103, 105, 0x30017, // [21]
	},
	NumStmt: [22]uint16{
		3, // 0
		3, // 1
		1, // 2
		3, // 3
		3, // 4
		1, // 5
		1, // 6
		1, // 7
		1, // 8
		3, // 9
		1, // 10
		3, // 11
		1, // 12
		2, // 13
		2, // 14
		1, // 15
		1, // 16
		2, // 17
		1, // 18
		1, // 19
		7, // 20
		1, // 21
	},
}
var _ = _cover_atomic_.LoadUint32
