//line /home/cooper/go/src/github.com/hyperledger/fabric/orderer/common/blockcutter/blockcutter.go:1
/*
Copyright IBM Corp. All Rights Reserved.

SPDX-License-Identifier: Apache-2.0
*/

package blockcutter; import _cover_atomic_ "sync/atomic"

import (
	"time"

	"github.com/hyperledger/fabric/common/channelconfig"
	"github.com/hyperledger/fabric/common/flogging"
	cb "github.com/hyperledger/fabric/protos/common"
)

var logger = flogging.MustGetLogger("orderer.common.blockcutter")

type OrdererConfigFetcher interface {
	OrdererConfig() (channelconfig.Orderer, bool)
}

// Receiver defines a sink for the ordered broadcast messages
type Receiver interface {
	// Ordered should be invoked sequentially as messages are ordered
	// Each batch in `messageBatches` will be wrapped into a block.
	// `pending` indicates if there are still messages pending in the receiver.
	Ordered(msg *cb.Envelope) (messageBatches [][]*cb.Envelope, pending bool)

	// Cut returns the current batch and starts a new one
	Cut() []*cb.Envelope
}

type receiver struct {
	sharedConfigFetcher   OrdererConfigFetcher
	pendingBatch          []*cb.Envelope
	pendingBatchSizeBytes uint32

	PendingBatchStartTime time.Time
	ChannelID             string
	Metrics               *Metrics
}

// NewReceiverImpl creates a Receiver implementation based on the given configtxorderer manager
func NewReceiverImpl(channelID string, sharedConfigFetcher OrdererConfigFetcher, metrics *Metrics) Receiver {_cover_atomic_.AddUint32(&GoCover_0_356536373066393635313431.Count[0], 1);
	return &receiver{
		sharedConfigFetcher: sharedConfigFetcher,
		Metrics:             metrics,
		ChannelID:           channelID,
	}
}

// Ordered should be invoked sequentially as messages are ordered
//
// messageBatches length: 0, pending: false
//   - impossible, as we have just received a message
// messageBatches length: 0, pending: true
//   - no batch is cut and there are messages pending
// messageBatches length: 1, pending: false
//   - the message count reaches BatchSize.MaxMessageCount
// messageBatches length: 1, pending: true
//   - the current message will cause the pending batch size in bytes to exceed BatchSize.PreferredMaxBytes.
// messageBatches length: 2, pending: false
//   - the current message size in bytes exceeds BatchSize.PreferredMaxBytes, therefore isolated in its own batch.
// messageBatches length: 2, pending: true
//   - impossible
//
// Note that messageBatches can not be greater than 2.
func (r *receiver) Ordered(msg *cb.Envelope) (messageBatches [][]*cb.Envelope, pending bool) {_cover_atomic_.AddUint32(&GoCover_0_356536373066393635313431.Count[1], 1);
	if len(r.pendingBatch) == 0 {_cover_atomic_.AddUint32(&GoCover_0_356536373066393635313431.Count[7], 1);
		// We are beginning a new batch, mark the time
		r.PendingBatchStartTime = time.Now()
	}

	_cover_atomic_.AddUint32(&GoCover_0_356536373066393635313431.Count[2], 1);ordererConfig, ok := r.sharedConfigFetcher.OrdererConfig()
	if !ok {_cover_atomic_.AddUint32(&GoCover_0_356536373066393635313431.Count[8], 1);
		logger.Panicf("Could not retrieve orderer config to query batch parameters, block cutting is not possible")
	}

	_cover_atomic_.AddUint32(&GoCover_0_356536373066393635313431.Count[3], 1);batchSize := ordererConfig.BatchSize()

	messageSizeBytes := messageSizeBytes(msg)
	if messageSizeBytes > batchSize.PreferredMaxBytes {_cover_atomic_.AddUint32(&GoCover_0_356536373066393635313431.Count[9], 1);
		logger.Debugf("The current message, with %v bytes, is larger than the preferred batch size of %v bytes and will be isolated.", messageSizeBytes, batchSize.PreferredMaxBytes)

		// cut pending batch, if it has any messages
		if len(r.pendingBatch) > 0 {_cover_atomic_.AddUint32(&GoCover_0_356536373066393635313431.Count[11], 1);
			messageBatch := r.Cut()
			messageBatches = append(messageBatches, messageBatch)
		}

		// create new batch with single message
		_cover_atomic_.AddUint32(&GoCover_0_356536373066393635313431.Count[10], 1);messageBatches = append(messageBatches, []*cb.Envelope{msg})

		// Record that this batch took no time to fill
		r.Metrics.BlockFillDuration.With("channel", r.ChannelID).Observe(0)

		return
	}

	_cover_atomic_.AddUint32(&GoCover_0_356536373066393635313431.Count[4], 1);messageWillOverflowBatchSizeBytes := r.pendingBatchSizeBytes+messageSizeBytes > batchSize.PreferredMaxBytes

	if messageWillOverflowBatchSizeBytes {_cover_atomic_.AddUint32(&GoCover_0_356536373066393635313431.Count[12], 1);
		logger.Debugf("The current message, with %v bytes, will overflow the pending batch of %v bytes.", messageSizeBytes, r.pendingBatchSizeBytes)
		logger.Debugf("Pending batch would overflow if current message is added, cutting batch now.")
		messageBatch := r.Cut()
		r.PendingBatchStartTime = time.Now()
		messageBatches = append(messageBatches, messageBatch)
	}

	_cover_atomic_.AddUint32(&GoCover_0_356536373066393635313431.Count[5], 1);logger.Debugf("Enqueuing message into batch")
	r.pendingBatch = append(r.pendingBatch, msg)
	r.pendingBatchSizeBytes += messageSizeBytes
	pending = true

	if uint32(len(r.pendingBatch)) >= batchSize.MaxMessageCount {_cover_atomic_.AddUint32(&GoCover_0_356536373066393635313431.Count[13], 1);
		logger.Debugf("Batch size met, cutting batch")
		messageBatch := r.Cut()
		messageBatches = append(messageBatches, messageBatch)
		pending = false
	}

	_cover_atomic_.AddUint32(&GoCover_0_356536373066393635313431.Count[6], 1);return
}

// Cut returns the current batch and starts a new one
func (r *receiver) Cut() []*cb.Envelope {_cover_atomic_.AddUint32(&GoCover_0_356536373066393635313431.Count[14], 1);
	r.Metrics.BlockFillDuration.With("channel", r.ChannelID).Observe(time.Since(r.PendingBatchStartTime).Seconds())
	r.PendingBatchStartTime = time.Time{}
	batch := r.pendingBatch
	r.pendingBatch = nil
	r.pendingBatchSizeBytes = 0
	return batch
}

func messageSizeBytes(message *cb.Envelope) uint32 {_cover_atomic_.AddUint32(&GoCover_0_356536373066393635313431.Count[15], 1);
	return uint32(len(message.Payload) + len(message.Signature))
}

var GoCover_0_356536373066393635313431 = struct {
	Count     [16]uint32
	Pos       [3 * 16]uint32
	NumStmt   [16]uint16
} {
	Pos: [3 * 16]uint32{
		45, 51, 0x2006d, // [0]
		69, 70, 0x1e005e, // [1]
		75, 76, 0x90002, // [2]
		80, 83, 0x340002, // [3]
		101, 103, 0x270002, // [4]
		111, 116, 0x3e0002, // [5]
		123, 123, 0x80002, // [6]
		70, 73, 0x3001e, // [7]
		76, 78, 0x30009, // [8]
		83, 87, 0x1e0034, // [9]
		93, 98, 0x90003, // [10]
		87, 90, 0x4001e, // [11]
		103, 109, 0x30027, // [12]
		116, 121, 0x3003e, // [13]
		127, 134, 0x20029, // [14]
		136, 138, 0x20034, // [15]
	},
	NumStmt: [16]uint16{
		1, // 0
		1, // 1
		2, // 2
		3, // 3
		2, // 4
		5, // 5
		1, // 6
		1, // 7
		1, // 8
		2, // 9
		3, // 10
		2, // 11
		5, // 12
		4, // 13
		6, // 14
		1, // 15
	},
}
var _ = _cover_atomic_.LoadUint32
