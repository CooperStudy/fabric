//line /home/cooper/go/src/github.com/hyperledger/fabric/core/container/controller.go:1
/*
Copyright IBM Corp. All Rights Reserved.

SPDX-License-Identifier: Apache-2.0
*/

package container; import _cover_atomic_ "sync/atomic"

import (
	"context"
	"fmt"
	"io"
	"sync"

	"github.com/hyperledger/fabric/common/flogging"
	"github.com/hyperledger/fabric/core/chaincode/platforms"
	"github.com/hyperledger/fabric/core/container/ccintf"
	pb "github.com/hyperledger/fabric/protos/peer"
)

type VMProvider interface {
	NewVM() VM
}

type Builder interface {
	Build() (io.Reader, error)
}

//VM is an abstract virtual image for supporting arbitrary virual machines
type VM interface {
	Start(ccid ccintf.CCID, args []string, env []string, filesToUpload map[string][]byte, builder Builder) error
	Stop(ccid ccintf.CCID, timeout uint, dontkill bool, dontremove bool) error
	HealthCheck(context.Context) error
}

type refCountedLock struct {
	refCount int
	lock     *sync.RWMutex
}

//VMController - manages VMs
//   . abstract construction of different types of VMs (we only care about Docker for now)
//   . manage lifecycle of VM (start with build, start, stop ...
//     eventually probably need fine grained management)
type VMController struct {
	sync.RWMutex
	containerLocks map[string]*refCountedLock
	vmProviders    map[string]VMProvider
}

var vmLogger = flogging.MustGetLogger("container")

// NewVMController creates a new instance of VMController
func NewVMController(vmProviders map[string]VMProvider) *VMController {_cover_atomic_.AddUint32(&GoCover_0_323339663866653731303137.Count[0], 1);
	return &VMController{
		containerLocks: make(map[string]*refCountedLock),
		vmProviders:    vmProviders,
	}
}

func (vmc *VMController) newVM(typ string) VM {_cover_atomic_.AddUint32(&GoCover_0_323339663866653731303137.Count[1], 1);
	v, ok := vmc.vmProviders[typ]
	if !ok {_cover_atomic_.AddUint32(&GoCover_0_323339663866653731303137.Count[3], 1);
		vmLogger.Panicf("Programming error: unsupported VM type: %s", typ)
	}
	_cover_atomic_.AddUint32(&GoCover_0_323339663866653731303137.Count[2], 1);return v.NewVM()
}

func (vmc *VMController) lockContainer(id string) {_cover_atomic_.AddUint32(&GoCover_0_323339663866653731303137.Count[4], 1);
	//get the container lock under global lock
	vmc.Lock()
	var refLck *refCountedLock
	var ok bool
	if refLck, ok = vmc.containerLocks[id]; !ok {_cover_atomic_.AddUint32(&GoCover_0_323339663866653731303137.Count[6], 1);
		refLck = &refCountedLock{refCount: 1, lock: &sync.RWMutex{}}
		vmc.containerLocks[id] = refLck
	} else{ _cover_atomic_.AddUint32(&GoCover_0_323339663866653731303137.Count[7], 1);{
		refLck.refCount++
		vmLogger.Debugf("refcount %d (%s)", refLck.refCount, id)
	}}
	_cover_atomic_.AddUint32(&GoCover_0_323339663866653731303137.Count[5], 1);vmc.Unlock()
	vmLogger.Debugf("waiting for container(%s) lock", id)
	refLck.lock.Lock()
	vmLogger.Debugf("got container (%s) lock", id)
}

func (vmc *VMController) unlockContainer(id string) {_cover_atomic_.AddUint32(&GoCover_0_323339663866653731303137.Count[8], 1);
	vmc.Lock()
	if refLck, ok := vmc.containerLocks[id]; ok {_cover_atomic_.AddUint32(&GoCover_0_323339663866653731303137.Count[10], 1);
		if refLck.refCount <= 0 {_cover_atomic_.AddUint32(&GoCover_0_323339663866653731303137.Count[12], 1);
			panic("refcnt <= 0")
		}
		_cover_atomic_.AddUint32(&GoCover_0_323339663866653731303137.Count[11], 1);refLck.lock.Unlock()
		if refLck.refCount--; refLck.refCount == 0 {_cover_atomic_.AddUint32(&GoCover_0_323339663866653731303137.Count[13], 1);
			vmLogger.Debugf("container lock deleted(%s)", id)
			delete(vmc.containerLocks, id)
		}
	} else{ _cover_atomic_.AddUint32(&GoCover_0_323339663866653731303137.Count[14], 1);{
		vmLogger.Debugf("no lock to unlock(%s)!!", id)
	}}
	_cover_atomic_.AddUint32(&GoCover_0_323339663866653731303137.Count[9], 1);vmc.Unlock()
}

//VMCReq - all requests should implement this interface.
//The context should be passed and tested at each layer till we stop
//note that we'd stop on the first method on the stack that does not
//take context
type VMCReq interface {
	Do(v VM) error
	GetCCID() ccintf.CCID
}

//StartContainerReq - properties for starting a container.
type StartContainerReq struct {
	ccintf.CCID
	Builder       Builder
	Args          []string
	Env           []string
	FilesToUpload map[string][]byte
}

// PlatformBuilder implements the Build interface using
// the platforms package GenerateDockerBuild function.
// XXX This is a pretty awkward spot for the builder, it should
// really probably be pushed into the dockercontroller, as it only
// builds docker images, but, doing so would require contaminating
// the dockercontroller package with the CDS, which is also
// undesirable.
type PlatformBuilder struct {
	Type             string
	Path             string
	Name             string
	Version          string
	CodePackage      []byte
	PlatformRegistry *platforms.Registry
}

// Build a tar stream based on the CDS
func (b *PlatformBuilder) Build() (io.Reader, error) {_cover_atomic_.AddUint32(&GoCover_0_323339663866653731303137.Count[15], 1);
	return b.PlatformRegistry.GenerateDockerBuild(
		b.Type,
		b.Path,
		b.Name,
		b.Version,
		b.CodePackage,
	)
}

func (si StartContainerReq) Do(v VM) error {_cover_atomic_.AddUint32(&GoCover_0_323339663866653731303137.Count[16], 1);
	return v.Start(si.CCID, si.Args, si.Env, si.FilesToUpload, si.Builder)
}

func (si StartContainerReq) GetCCID() ccintf.CCID {_cover_atomic_.AddUint32(&GoCover_0_323339663866653731303137.Count[17], 1);
	return si.CCID
}

//StopContainerReq - properties for stopping a container.
type StopContainerReq struct {
	ccintf.CCID
	Timeout uint
	//by default we will kill the container after stopping
	Dontkill bool
	//by default we will remove the container after killing
	Dontremove bool
}

func (si StopContainerReq) Do(v VM) error {_cover_atomic_.AddUint32(&GoCover_0_323339663866653731303137.Count[18], 1);
	return v.Stop(si.CCID, si.Timeout, si.Dontkill, si.Dontremove)
}

func (si StopContainerReq) GetCCID() ccintf.CCID {_cover_atomic_.AddUint32(&GoCover_0_323339663866653731303137.Count[19], 1);
	return si.CCID
}

func (vmc *VMController) Process(vmtype string, req VMCReq) error {_cover_atomic_.AddUint32(&GoCover_0_323339663866653731303137.Count[20], 1);
	v := vmc.newVM(vmtype)
	ccid := req.GetCCID()
	id := ccid.GetName()

	vmc.lockContainer(id)
	defer vmc.unlockContainer(id)
	return req.Do(v)
}

// GetChaincodePackageBytes creates bytes for docker container generation using the supplied chaincode specification
func GetChaincodePackageBytes(pr *platforms.Registry, spec *pb.ChaincodeSpec) ([]byte, error) {_cover_atomic_.AddUint32(&GoCover_0_323339663866653731303137.Count[21], 1);
	if spec == nil || spec.ChaincodeId == nil {_cover_atomic_.AddUint32(&GoCover_0_323339663866653731303137.Count[23], 1);
		return nil, fmt.Errorf("invalid chaincode spec")
	}

	_cover_atomic_.AddUint32(&GoCover_0_323339663866653731303137.Count[22], 1);return pr.GetDeploymentPayload(spec.CCType(), spec.Path())
}

var GoCover_0_323339663866653731303137 = struct {
	Count     [24]uint32
	Pos       [3 * 24]uint32
	NumStmt   [24]uint16
} {
	Pos: [3 * 24]uint32{
		54, 59, 0x20047, // [0]
		61, 63, 0x9002f, // [1]
		66, 66, 0x120002, // [2]
		63, 65, 0x30009, // [3]
		69, 74, 0x2e0033, // [4]
		81, 84, 0x300002, // [5]
		74, 77, 0x3002e, // [6]
		77, 80, 0x30008, // [7]
		87, 89, 0x2e0035, // [8]
		101, 101, 0xe0002, // [9]
		89, 90, 0x1b002e, // [10]
		93, 94, 0x2e0003, // [11]
		90, 91, 0x18001b, // [12]
		94, 97, 0x4002e, // [13]
		98, 100, 0x30008, // [14]
		139, 147, 0x20036, // [15]
		149, 151, 0x2002c, // [16]
		153, 155, 0x20033, // [17]
		167, 169, 0x2002b, // [18]
		171, 173, 0x20032, // [19]
		175, 183, 0x20043, // [20]
		186, 187, 0x2c005f, // [21]
		191, 191, 0x3c0002, // [22]
		187, 189, 0x3002c, // [23]
	},
	NumStmt: [24]uint16{
		1, // 0
		2, // 1
		1, // 2
		1, // 3
		4, // 4
		4, // 5
		2, // 6
		2, // 7
		2, // 8
		1, // 9
		1, // 10
		2, // 11
		1, // 12
		2, // 13
		1, // 14
		1, // 15
		1, // 16
		1, // 17
		1, // 18
		1, // 19
		6, // 20
		1, // 21
		1, // 22
		1, // 23
	},
}
var _ = _cover_atomic_.LoadUint32
