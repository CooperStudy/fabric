//line /home/cooper/go/src/github.com/hyperledger/fabric/core/ledger/kvledger/txmgmt/rwsetutil/query_results_helper.go:1
/*
Copyright IBM Corp. All Rights Reserved.

SPDX-License-Identifier: Apache-2.0
*/

package rwsetutil; import _cover_atomic_ "sync/atomic"

import (
	"fmt"

	"github.com/golang/protobuf/proto"
	"github.com/hyperledger/fabric/bccsp"
	bccspfactory "github.com/hyperledger/fabric/bccsp/factory"
	"github.com/hyperledger/fabric/protos/ledger/rwset/kvrwset"
	"github.com/pkg/errors"
)

// MerkleTreeLevel used for representing a level of the merkle tree
type MerkleTreeLevel uint32

// Hash represents bytes of a hash
type Hash []byte

const (
	leafLevel = MerkleTreeLevel(1)
)

var (
	hashOpts = &bccsp.SHA256Opts{}
)

// RangeQueryResultsHelper helps preparing range query results for phantom items detection during validation.
// The results are expected to be fed as they are being iterated over.
// If the `hashingEnabled` is set to true, a merkle tree is built of the hashes over the results.
// The merkle tree helps reducing the size of the RWSet which otherwise would need to store all the raw KVReads
//
// The mental model of the tree can be described as below:
// All the results are treated as leaf nodes (level 0) of the tree. Next up level of the tree is built by collecting 'maxDegree + 1'
// items from the previous level and hashing the entire collection.
// Further upper levels of the tree are built in similar manner however the only difference is that unlike level-0
// (where collection consists of raw KVReads), collection at level 1 and above, consists of the hashes
// (of the collection of previous level).
// This is repeated until we reach at a level where we are left with the number of items less than or equals to `maxDegree`.
// In the last collection, the number of items can be less than 'maxDegree' (except if this is the only collection at the given level).
//
// As a result, if the number of total input results are less than or equals to 'maxDegree', no hashing is performed at all.
// And the final output of the computation is either the collection of raw results (if less that or equals to 'maxDegree') or
// a collection of hashes (that or equals to 'maxDegree') at some level in the tree.
//
// `AddResult` function should be invoke to supply the next result and at the end `Done` function should be invoked.
// The `Done` function does the final processing and returns the final output
type RangeQueryResultsHelper struct {
	pendingResults []*kvrwset.KVRead
	mt             *merkleTree
	maxDegree      uint32
	hashingEnabled bool
}

// NewRangeQueryResultsHelper constructs a RangeQueryResultsHelper
func NewRangeQueryResultsHelper(enableHashing bool, maxDegree uint32) (*RangeQueryResultsHelper, error) {_cover_atomic_.AddUint32(&GoCover_0_353735386332653438306431.Count[0], 1);
	helper := &RangeQueryResultsHelper{pendingResults: nil,
		hashingEnabled: enableHashing,
		maxDegree:      maxDegree,
		mt:             nil}
	if enableHashing {_cover_atomic_.AddUint32(&GoCover_0_353735386332653438306431.Count[2], 1);
		var err error
		if helper.mt, err = newMerkleTree(maxDegree); err != nil {_cover_atomic_.AddUint32(&GoCover_0_353735386332653438306431.Count[3], 1);
			return nil, err
		}
	}
	_cover_atomic_.AddUint32(&GoCover_0_353735386332653438306431.Count[1], 1);return helper, nil
}

// AddResult adds a new query result for processing.
// Put the result into the list of pending results. If the number of pending results exceeds `maxDegree`,
// consume the results for incrementally update the merkle tree
func (helper *RangeQueryResultsHelper) AddResult(kvRead *kvrwset.KVRead) error {_cover_atomic_.AddUint32(&GoCover_0_353735386332653438306431.Count[4], 1);
	logger.Debug("Adding a result")
	helper.pendingResults = append(helper.pendingResults, kvRead)
	if helper.hashingEnabled && uint32(len(helper.pendingResults)) > helper.maxDegree {_cover_atomic_.AddUint32(&GoCover_0_353735386332653438306431.Count[6], 1);
		logger.Debug("Processing the accumulated results")
		if err := helper.processPendingResults(); err != nil {_cover_atomic_.AddUint32(&GoCover_0_353735386332653438306431.Count[7], 1);
			return err
		}
	}
	_cover_atomic_.AddUint32(&GoCover_0_353735386332653438306431.Count[5], 1);return nil
}

// Done processes any pending results if needed
// This returns the final pending results (i.e., []*KVRead) and hashes of the results (i.e., *MerkleSummary)
// Only one of these two will be non-nil (except when no results are ever added).
// `MerkleSummary` will be nil if and only if either `enableHashing` is set to false
// or the number of total results are less than `maxDegree`
func (helper *RangeQueryResultsHelper) Done() ([]*kvrwset.KVRead, *kvrwset.QueryReadsMerkleSummary, error) {_cover_atomic_.AddUint32(&GoCover_0_353735386332653438306431.Count[8], 1);
	// The merkle tree will be empty if total results are less than or equals to 'maxDegree'
	// i.e., not even once the results were processed for hashing
	if !helper.hashingEnabled || helper.mt.isEmpty() {_cover_atomic_.AddUint32(&GoCover_0_353735386332653438306431.Count[11], 1);
		return helper.pendingResults, nil, nil
	}
	_cover_atomic_.AddUint32(&GoCover_0_353735386332653438306431.Count[9], 1);if len(helper.pendingResults) != 0 {_cover_atomic_.AddUint32(&GoCover_0_353735386332653438306431.Count[12], 1);
		logger.Debug("Processing the pending results")
		if err := helper.processPendingResults(); err != nil {_cover_atomic_.AddUint32(&GoCover_0_353735386332653438306431.Count[13], 1);
			return helper.pendingResults, nil, err
		}
	}
	_cover_atomic_.AddUint32(&GoCover_0_353735386332653438306431.Count[10], 1);helper.mt.done()
	return helper.pendingResults, helper.mt.getSummery(), nil
}

// GetMerkleSummary return the current state of the MerkleSummary
// This intermediate state of the merkle tree helps during validation to detect a mismatch early on.
// That helps by not requiring to build the complete merkle tree during validation
// if there is a mismatch in early portion of the result-set.
func (helper *RangeQueryResultsHelper) GetMerkleSummary() *kvrwset.QueryReadsMerkleSummary {_cover_atomic_.AddUint32(&GoCover_0_353735386332653438306431.Count[14], 1);
	if !helper.hashingEnabled {_cover_atomic_.AddUint32(&GoCover_0_353735386332653438306431.Count[16], 1);
		return nil
	}
	_cover_atomic_.AddUint32(&GoCover_0_353735386332653438306431.Count[15], 1);return helper.mt.getSummery()
}

func (helper *RangeQueryResultsHelper) processPendingResults() error {_cover_atomic_.AddUint32(&GoCover_0_353735386332653438306431.Count[17], 1);
	var b []byte
	var err error
	if b, err = serializeKVReads(helper.pendingResults); err != nil {_cover_atomic_.AddUint32(&GoCover_0_353735386332653438306431.Count[20], 1);
		return err
	}
	_cover_atomic_.AddUint32(&GoCover_0_353735386332653438306431.Count[18], 1);helper.pendingResults = nil
	hash, err := bccspfactory.GetDefault().Hash(b, hashOpts)
	if err != nil {_cover_atomic_.AddUint32(&GoCover_0_353735386332653438306431.Count[21], 1);
		return err
	}
	_cover_atomic_.AddUint32(&GoCover_0_353735386332653438306431.Count[19], 1);helper.mt.update(hash)
	return nil
}

func serializeKVReads(kvReads []*kvrwset.KVRead) ([]byte, error) {_cover_atomic_.AddUint32(&GoCover_0_353735386332653438306431.Count[22], 1);
	return proto.Marshal(&kvrwset.QueryReads{KvReads: kvReads})
}

//////////// Merkle tree building code  ///////

type merkleTree struct {
	tree      map[MerkleTreeLevel][]Hash
	maxLevel  MerkleTreeLevel
	maxDegree uint32
}

func newMerkleTree(maxDegree uint32) (*merkleTree, error) {_cover_atomic_.AddUint32(&GoCover_0_353735386332653438306431.Count[23], 1);
	if maxDegree < 2 {_cover_atomic_.AddUint32(&GoCover_0_353735386332653438306431.Count[25], 1);
		return nil, errors.Errorf("maxDegree [%d] should not be less than 2 in the merkle tree", maxDegree)
	}
	_cover_atomic_.AddUint32(&GoCover_0_353735386332653438306431.Count[24], 1);return &merkleTree{make(map[MerkleTreeLevel][]Hash), 1, maxDegree}, nil
}

// update takes a hash that forms the next leaf level (level-1) node in the merkle tree.
// Also, complete the merkle tree as much as possible with the addition of this new leaf node -
// i.e. recursively build the higher level nodes and delete the underlying sub-tree.
func (m *merkleTree) update(nextLeafLevelHash Hash) error {_cover_atomic_.AddUint32(&GoCover_0_353735386332653438306431.Count[26], 1);
	logger.Debugf("Before update() = %s", m)
	defer logger.Debugf("After update() = %s", m)
	m.tree[leafLevel] = append(m.tree[leafLevel], nextLeafLevelHash)
	currentLevel := leafLevel
	for {_cover_atomic_.AddUint32(&GoCover_0_353735386332653438306431.Count[27], 1);
		currentLevelHashes := m.tree[currentLevel]
		if uint32(len(currentLevelHashes)) <= m.maxDegree {_cover_atomic_.AddUint32(&GoCover_0_353735386332653438306431.Count[31], 1);
			return nil
		}
		_cover_atomic_.AddUint32(&GoCover_0_353735386332653438306431.Count[28], 1);nextLevelHash, err := computeCombinedHash(currentLevelHashes)
		if err != nil {_cover_atomic_.AddUint32(&GoCover_0_353735386332653438306431.Count[32], 1);
			return err
		}
		_cover_atomic_.AddUint32(&GoCover_0_353735386332653438306431.Count[29], 1);delete(m.tree, currentLevel)
		nextLevel := currentLevel + 1
		m.tree[nextLevel] = append(m.tree[nextLevel], nextLevelHash)
		if nextLevel > m.maxLevel {_cover_atomic_.AddUint32(&GoCover_0_353735386332653438306431.Count[33], 1);
			m.maxLevel = nextLevel
		}
		_cover_atomic_.AddUint32(&GoCover_0_353735386332653438306431.Count[30], 1);currentLevel = nextLevel
	}
}

// done completes the merkle tree.
// There may have been some nodes that are at the levels lower than the maxLevel (maximum level seen by the tree so far).
// Make the parent nodes out of such nodes till we complete the tree at the level of maxLevel (or maxLevel+1).
func (m *merkleTree) done() error {_cover_atomic_.AddUint32(&GoCover_0_353735386332653438306431.Count[34], 1);
	logger.Debugf("Before done() = %s", m)
	defer logger.Debugf("After done() = %s", m)
	currentLevel := leafLevel
	var h Hash
	var err error
	for currentLevel < m.maxLevel {_cover_atomic_.AddUint32(&GoCover_0_353735386332653438306431.Count[37], 1);
		currentLevelHashes := m.tree[currentLevel]
		switch len(currentLevelHashes) {
		case 0:_cover_atomic_.AddUint32(&GoCover_0_353735386332653438306431.Count[39], 1);
			currentLevel++
			continue
		case 1:_cover_atomic_.AddUint32(&GoCover_0_353735386332653438306431.Count[40], 1);
			h = currentLevelHashes[0]
		default:_cover_atomic_.AddUint32(&GoCover_0_353735386332653438306431.Count[41], 1);
			if h, err = computeCombinedHash(currentLevelHashes); err != nil {_cover_atomic_.AddUint32(&GoCover_0_353735386332653438306431.Count[42], 1);
				return err
			}
		}
		_cover_atomic_.AddUint32(&GoCover_0_353735386332653438306431.Count[38], 1);delete(m.tree, currentLevel)
		currentLevel++
		m.tree[currentLevel] = append(m.tree[currentLevel], h)
	}

	_cover_atomic_.AddUint32(&GoCover_0_353735386332653438306431.Count[35], 1);finalHashes := m.tree[m.maxLevel]
	if uint32(len(finalHashes)) > m.maxDegree {_cover_atomic_.AddUint32(&GoCover_0_353735386332653438306431.Count[43], 1);
		delete(m.tree, m.maxLevel)
		m.maxLevel++
		combinedHash, err := computeCombinedHash(finalHashes)
		if err != nil {_cover_atomic_.AddUint32(&GoCover_0_353735386332653438306431.Count[45], 1);
			return err
		}
		_cover_atomic_.AddUint32(&GoCover_0_353735386332653438306431.Count[44], 1);m.tree[m.maxLevel] = []Hash{combinedHash}
	}
	_cover_atomic_.AddUint32(&GoCover_0_353735386332653438306431.Count[36], 1);return nil
}

func (m *merkleTree) getSummery() *kvrwset.QueryReadsMerkleSummary {_cover_atomic_.AddUint32(&GoCover_0_353735386332653438306431.Count[46], 1);
	return &kvrwset.QueryReadsMerkleSummary{MaxDegree: m.maxDegree,
		MaxLevel:       uint32(m.getMaxLevel()),
		MaxLevelHashes: hashesToBytes(m.getMaxLevelHashes())}
}

func (m *merkleTree) getMaxLevel() MerkleTreeLevel {_cover_atomic_.AddUint32(&GoCover_0_353735386332653438306431.Count[47], 1);
	return m.maxLevel
}

func (m *merkleTree) getMaxLevelHashes() []Hash {_cover_atomic_.AddUint32(&GoCover_0_353735386332653438306431.Count[48], 1);
	return m.tree[m.maxLevel]
}

func (m *merkleTree) isEmpty() bool {_cover_atomic_.AddUint32(&GoCover_0_353735386332653438306431.Count[49], 1);
	return m.maxLevel == 1 && len(m.tree[m.maxLevel]) == 0
}

func (m *merkleTree) String() string {_cover_atomic_.AddUint32(&GoCover_0_353735386332653438306431.Count[50], 1);
	return fmt.Sprintf("tree := %#v", m.tree)
}

func computeCombinedHash(hashes []Hash) (Hash, error) {_cover_atomic_.AddUint32(&GoCover_0_353735386332653438306431.Count[51], 1);
	combinedHash := []byte{}
	for _, h := range hashes {_cover_atomic_.AddUint32(&GoCover_0_353735386332653438306431.Count[53], 1);
		combinedHash = append(combinedHash, h...)
	}
	_cover_atomic_.AddUint32(&GoCover_0_353735386332653438306431.Count[52], 1);return bccspfactory.GetDefault().Hash(combinedHash, hashOpts)
}

func hashesToBytes(hashes []Hash) [][]byte {_cover_atomic_.AddUint32(&GoCover_0_353735386332653438306431.Count[54], 1);
	b := [][]byte{}
	for _, hash := range hashes {_cover_atomic_.AddUint32(&GoCover_0_353735386332653438306431.Count[56], 1);
		b = append(b, hash)
	}
	_cover_atomic_.AddUint32(&GoCover_0_353735386332653438306431.Count[55], 1);return b
}

var GoCover_0_353735386332653438306431 = struct {
	Count     [57]uint32
	Pos       [3 * 57]uint32
	NumStmt   [57]uint16
} {
	Pos: [3 * 57]uint32{
		61, 66, 0x130069, // [0]
		72, 72, 0x140002, // [1]
		66, 68, 0x3c0013, // [2]
		68, 70, 0x4003c, // [3]
		78, 81, 0x540050, // [4]
		87, 87, 0xc0002, // [5]
		81, 83, 0x380054, // [6]
		83, 85, 0x40038, // [7]
		95, 98, 0x33006c, // [8]
		101, 101, 0x250002, // [9]
		107, 108, 0x3b0002, // [10]
		98, 100, 0x30033, // [11]
		101, 103, 0x380025, // [12]
		103, 105, 0x40038, // [13]
		115, 116, 0x1c005c, // [14]
		119, 119, 0x1f0002, // [15]
		116, 118, 0x3001c, // [16]
		122, 125, 0x420046, // [17]
		128, 130, 0x100002, // [18]
		133, 134, 0xc0002, // [19]
		125, 127, 0x30042, // [20]
		130, 132, 0x30010, // [21]
		137, 139, 0x20042, // [22]
		149, 150, 0x13003b, // [23]
		153, 153, 0x490002, // [24]
		150, 152, 0x30013, // [25]
		159, 164, 0x6003b, // [26]
		164, 166, 0x350006, // [27]
		169, 170, 0x110003, // [28]
		173, 176, 0x1d0003, // [29]
		179, 179, 0x1b0003, // [30]
		166, 168, 0x40035, // [31]
		170, 172, 0x40011, // [32]
		176, 178, 0x4001d, // [33]
		186, 192, 0x200023, // [34]
		210, 211, 0x2c0002, // [35]
		220, 220, 0xc0002, // [36]
		192, 194, 0x220020, // [37]
		205, 207, 0x390003, // [38]
		195, 197, 0xc000a, // [39]
		198, 199, 0x1d000a, // [40]
		200, 201, 0x44000b, // [41]
		201, 203, 0x50044, // [42]
		211, 215, 0x11002c, // [43]
		218, 218, 0x2c0003, // [44]
		215, 217, 0x40011, // [45]
		223, 227, 0x20044, // [46]
		229, 231, 0x20034, // [47]
		233, 235, 0x20031, // [48]
		237, 239, 0x20025, // [49]
		241, 243, 0x20026, // [50]
		245, 247, 0x1b0037, // [51]
		250, 250, 0x3f0002, // [52]
		247, 249, 0x3001b, // [53]
		253, 255, 0x1e002c, // [54]
		258, 258, 0xa0002, // [55]
		255, 257, 0x3001e, // [56]
	},
	NumStmt: [57]uint16{
		2, // 0
		1, // 1
		2, // 2
		1, // 3
		3, // 4
		1, // 5
		2, // 6
		1, // 7
		1, // 8
		1, // 9
		2, // 10
		1, // 11
		2, // 12
		1, // 13
		1, // 14
		1, // 15
		1, // 16
		3, // 17
		3, // 18
		2, // 19
		1, // 20
		1, // 21
		1, // 22
		1, // 23
		1, // 24
		1, // 25
		5, // 26
		2, // 27
		2, // 28
		4, // 29
		1, // 30
		1, // 31
		1, // 32
		1, // 33
		6, // 34
		2, // 35
		1, // 36
		2, // 37
		3, // 38
		2, // 39
		1, // 40
		1, // 41
		1, // 42
		4, // 43
		1, // 44
		1, // 45
		1, // 46
		1, // 47
		1, // 48
		1, // 49
		1, // 50
		2, // 51
		1, // 52
		1, // 53
		2, // 54
		1, // 55
		1, // 56
	},
}
var _ = _cover_atomic_.LoadUint32
